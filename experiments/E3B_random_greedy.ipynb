{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if \"dir_changed\" not in locals():\n",
    "    os.chdir(\"..\")\n",
    "    loaded = load_dotenv(override=True)\n",
    "    dir_changed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linus/Repos/prompt_optimization_optimal_evaluation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from prompt_optimization.operators.mutation import Mutation\n",
    "from prompt_optimization.utils.data import load_summeval_jsonl\n",
    "from prompt_optimization.prompt_eval.exact_match_evaluator import (\n",
    "    ExactMatchEvaluatorConfig,\n",
    "    ExactMatchEvaluator,\n",
    ")\n",
    "from prompt_optimization.utils.prompt import prompt_set_union\n",
    "\n",
    "from prompt_optimization.types.prompt import Prompt\n",
    "from prompt_optimization.utils.data import (\n",
    "    load_rewardbench_references,\n",
    "    CHAT_SUBSETS,\n",
    "    CHAT_HARD_SUBSETS,\n",
    "    SAFETY_SUBSETS,\n",
    "    REASONING_SUBSETS,\n",
    ")\n",
    "from prompt_optimization.prompt_eval.dict_similarity_evaluator2 import (\n",
    "    DictSimilarityEvaluator2,\n",
    "    DictSimilarityEvaluator2Config,\n",
    ")\n",
    "from prompt_optimization.llm.open_ai_compliant_llm_engine import (\n",
    "    OpenAICompliantLLMEngine,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = load_summeval_jsonl(\"data/summeval.jsonl\")\n",
    "\n",
    "random.seed(123)\n",
    "references_shuffled = random.sample(references, len(references))\n",
    "\n",
    "se_train = references_shuffled[:25]\n",
    "se_test = references_shuffled[50:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples_per_subset = 1\n",
    "validations_per_subset = 8\n",
    "\n",
    "subsets_map = {\n",
    "    \"chat\": CHAT_SUBSETS,\n",
    "    \"chat_hard\": CHAT_HARD_SUBSETS,\n",
    "    \"safety\": SAFETY_SUBSETS,\n",
    "    \"reasoning\": REASONING_SUBSETS,\n",
    "}\n",
    "\n",
    "subsets_all = [subset for subsets in subsets_map.values() for subset in subsets]\n",
    "\n",
    "subset_data = {subset: load_rewardbench_references([subset]) for subset in subsets_all}\n",
    "\n",
    "rb_train = []\n",
    "for subset in subsets_all:\n",
    "    rb_train.extend(subset_data[subset][:training_examples_per_subset])\n",
    "\n",
    "rb_test = []\n",
    "for category, subsets in subsets_map.items():\n",
    "    for subset in subsets:\n",
    "        rb_test.extend(\n",
    "            subset_data[subset][\n",
    "                training_examples_per_subset : training_examples_per_subset\n",
    "                + validations_per_subset\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# shuffle rb_train\n",
    "random.seed(123)\n",
    "rb_train = random.sample(rb_train, len(rb_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama31_70b = OpenAICompliantLLMEngine(\n",
    "    base_url=os.environ[\"DEEPINFRA_BASE_URL\"],\n",
    "    api_keys=os.environ[\"DEEPINFRA_API_KEY_A3\"],\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    ")\n",
    "llama31_70b_eval = OpenAICompliantLLMEngine(\n",
    "    base_url=os.environ[\"DEEPINFRA_BASE_URL\"],\n",
    "    api_keys=os.environ[\"DEEPINFRA_API_KEY_A4\"],\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "llama31_70b_b = OpenAICompliantLLMEngine(\n",
    "    base_url=os.environ[\"DEEPINFRA_BASE_URL\"],\n",
    "    api_keys=os.environ[\"DEEPINFRA_API_KEY_A1\"],\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    ")\n",
    "llama31_70b_eval_b = OpenAICompliantLLMEngine(\n",
    "    base_url=os.environ[\"DEEPINFRA_BASE_URL\"],\n",
    "    api_keys=os.environ[\"DEEPINFRA_API_KEY_A2\"],\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_prompt = \"\"\"{rnd}\n",
    "Generate a variation of the following prompt:\n",
    "\n",
    "<PROMPT>\n",
    "{prompt}\n",
    "</PROMPT>\n",
    "\n",
    "The generated prompt should be contain all information and instructions of the original prompt, but worded in a different way.\n",
    "Important: only change the original prompt a tiny bit!\n",
    "\n",
    "Provide the new instruction inside <INSTR> tags like this:\n",
    "<INSTR>...</INSTR>\n",
    "\"\"\"\n",
    "\n",
    "se_system = \"\"\"You are an expert system at evaluating created summaries on the dimensions of coherence, consistency, fluency, and relevance.\"\"\"\n",
    "\n",
    "se_instr1 = \"\"\"\n",
    "You will evaluate the quality of a given summary, with respect to a reference on four dimensions.\n",
    "\n",
    "Output your evaluation as a JSON object like this:\n",
    "{\n",
    "    \"coherence: <float between 1 and 5>\",\n",
    "    \"consistency: <float between 1 and 5>\",\n",
    "    \"fluency: <float between 1 and 5>\",\n",
    "    \"relevance: <float between 1 and 5>\"\n",
    "}\n",
    "\n",
    "Before you output the JSON dict, lay out your reasoning step by step.\n",
    "\"\"\"\n",
    "\n",
    "se_instr2 = \"\"\"\n",
    "My friend gave me a summary. Those summaries are usually not very good (honstely). Can you do me a\n",
    "favor and review another one by him? By very fair please. Put down your thinking before you provide\n",
    "the final verdict on 4 dimensions: coherence, consistency, fluency, and relevance.\n",
    "\n",
    "Output your evaluation as a JSON object like this:\n",
    "{\n",
    "    \"coherence: <between 1 and 5>\",\n",
    "    \"consistency: <between 1 and 5>\",\n",
    "    \"fluency: <between 1 and 5>\",\n",
    "    \"relevance: <between 1 and 5>\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "rb_system = \"You are a fair judge assistant tasked with providing clear, objective feedback based on specific criteria, ensuring each assessment reflects the absolute standards set for performance.\"\n",
    "\n",
    "rb_prompt_v2 = (\n",
    "    \"Please act as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user question displayed below. \"\n",
    "    \"You should choose the assistant that follows the user's instructions and answers the user's question better. Your evaluation should consider \"\n",
    "    \"factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of their responses. Begin your evaluation by \"\n",
    "    \"comparing the two responses and provide a short explanation. Avoid any position biases and ensure that the order in which the responses were \"\n",
    "    \"presented does not influence your decision. Do not allow the length of the responses to influence your evaluation. Do not favor certain names \"\n",
    "    \"of the assistants. Be as objective as possible. After providing your explanation, output your final verdict by strictly following this format: \"\n",
    "    '\"[[A]]\" if assistant A is better, \"[[B]]\" if assistant B is better.'  # removed tie option as , and \\\"[[C]]\\ \" for a tie\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_set_se = [Prompt(prompt=se_instructions)]\n",
    "\n",
    "prompt_set_rb = [Prompt(prompt=rb_prompt_v2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainset evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "conf = DictSimilarityEvaluator2Config(\n",
    "    testset=se_train[:k],\n",
    "    llm=llama31_70b_eval,\n",
    "    validation=False,\n",
    "    system_prompt=se_system,\n",
    "    instruction_execution_prompt=\"{input}\\n\\n{instruction}\",\n",
    ")\n",
    "se_metric = DictSimilarityEvaluator2(conf)\n",
    "\n",
    "conf = ExactMatchEvaluatorConfig(\n",
    "    testset=rb_train[:k],\n",
    "    llm=llama31_70b_eval_b,\n",
    "    validation=False,\n",
    "    output_extraction_regex=r\"\\[\\[.*\\]\\]\",\n",
    "    system_prompt=rb_system,\n",
    "    instruction_execution_prompt=\"{instruction}\\n\\n{input}\",\n",
    ")\n",
    "rb_metric = ExactMatchEvaluator(conf)\n",
    "\n",
    "conf = DictSimilarityEvaluator2Config(\n",
    "    testset=se_test,\n",
    "    llm=llama31_70b_eval,\n",
    "    validation=True,\n",
    "    system_prompt=se_system,\n",
    "    instruction_execution_prompt=\"{input}\\n\\n{instruction}\",\n",
    ")\n",
    "se_val = DictSimilarityEvaluator2(conf)\n",
    "\n",
    "conf = ExactMatchEvaluatorConfig(\n",
    "    testset=rb_test,\n",
    "    llm=llama31_70b_eval_b,\n",
    "    validation=True,\n",
    "    output_extraction_regex=r\"\\[\\[.*\\]\\]\",\n",
    "    system_prompt=rb_system,\n",
    "    instruction_execution_prompt=\"{instruction}\\n\\n{input}\",\n",
    ")\n",
    "rb_val = ExactMatchEvaluator(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_non_val(prompt_set):\n",
    "    return sorted(\n",
    "        [p for p in prompt_set if p.mean_validation_score is None],\n",
    "        key=lambda p: p.mean_score,\n",
    "        reverse=True,\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval on prompt: Please act as an impartial jud...: 100%|██████████| 176/176 [00:00<00:00, 1306.17it/s]\n",
      "Eval on prompt set...: 100%|██████████| 10/10 [00:00<00:00, 967.19it/s]\n",
      "Eval on prompt set...: 100%|██████████| 11/11 [00:00<00:00, 835.90it/s]\n",
      "Eval on prompt: Assume the role of a neutral e...: 100%|██████████| 176/176 [00:00<00:00, 1261.51it/s]\n",
      "Eval on prompt set...: 100%|██████████| 12/12 [00:00<00:00, 1170.42it/s]\n",
      "Eval on prompt set...: 100%|██████████| 13/13 [00:00<00:00, 1195.19it/s]\n",
      "Eval on prompt set...: 100%|██████████| 14/14 [00:00<00:00, 71.30it/s]\n",
      "Eval on prompt set...: 100%|██████████| 15/15 [00:00<00:00, 1357.76it/s]\n",
      "Eval on prompt set...: 100%|██████████| 16/16 [00:00<00:00, 1403.80it/s]\n",
      "Eval on prompt set...: 100%|██████████| 17/17 [00:00<00:00, 1417.61it/s]\n",
      "Eval on prompt set...: 100%|██████████| 18/18 [00:00<00:00, 1414.45it/s]\n",
      "Eval on prompt set...: 100%|██████████| 19/19 [00:00<00:00, 2299.24it/s]\n",
      "Eval on prompt set...: 100%|██████████| 20/20 [00:00<00:00, 1932.73it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 25.80it/s]\n",
      "Eval on prompt set...: 100%|██████████| 21/21 [00:00<00:00, 1506.91it/s]\n",
      "Eval on prompt: Assume the role of an unbiased...: 100%|██████████| 176/176 [00:00<00:00, 1131.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[Prompt(prompt='Assess the summary's ability to distill the reference text's core idea [...] <rating from 1 to 5>\\n}' (len=399), mean_score=0.5276, mean_validation_score=0.4881, zero_score_cases=False)],\n",
       " [Prompt(prompt='Assume the role of an unbiased evaluator and assess the quality of the [...] ssistant B is superior.' (len=1004), mean_score=0.8000, mean_validation_score=0.8011, zero_score_cases=True)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "val_steps = [5, 10]\n",
    "\n",
    "mutator_se = Mutation(llama31_70b, meta_prompt=meta_prompt)\n",
    "mutator_rb = Mutation(llama31_70b_b, meta_prompt=meta_prompt)\n",
    "\n",
    "validation_tasks = []\n",
    "for step in tqdm(range(n)):\n",
    "    # trainset eval\n",
    "    await asyncio.gather(se_metric(prompt_set_se), rb_metric(prompt_set_rb))\n",
    "\n",
    "    # mutation\n",
    "    best_se = sorted(prompt_set_se, key=lambda x: x.mean_score, reverse=True)[0]\n",
    "    best_rb = sorted(prompt_set_rb, key=lambda x: x.mean_score, reverse=True)[0]\n",
    "\n",
    "    # validation\n",
    "    if step in val_steps:\n",
    "        await asyncio.gather(\n",
    "            se_val([best_non_val(prompt_set_se)]), rb_val([best_non_val(prompt_set_rb)])\n",
    "        )\n",
    "\n",
    "    new_prompts = await asyncio.gather(mutator_se([best_se]), mutator_rb([best_rb]))\n",
    "\n",
    "    prompt_set_se = prompt_set_union(prompt_set_se, new_prompts[0])\n",
    "    prompt_set_rb = prompt_set_union(prompt_set_rb, new_prompts[1])\n",
    "\n",
    "await asyncio.gather(se_metric(prompt_set_se), rb_metric(prompt_set_rb))\n",
    "\n",
    "await asyncio.gather(\n",
    "    se_val([best_non_val(prompt_set_se)]), rb_val([best_non_val(prompt_set_rb)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prompt(prompt='\\nYou will evaluate the quality of a given summary, with respect to a  [...] asoning step by step.\\n' (len=393), mean_score=0.4482, mean_validation_score=0.4819, zero_score_cases=False),\n",
       " Prompt(prompt='You will be assessing the quality of a provided summary in relation to [...] ngs for each dimension.' (len=472), mean_score=0.4394, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Assess the quality of a provided summary in relation to a reference te [...] he specified structure.' (len=457), mean_score=0.4273, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='You will be assessing the quality of a provided summary in relation to [...] behind your evaluation.' (len=529), mean_score=0.3140, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Assess the quality of a provided summary in relation to a reference te [...] at between 1 and 5>\"\\n}' (len=395), mean_score=0.4319, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='You will be assessing the quality of a provided summary in relation to [...] ach score step by step.' (len=464), mean_score=0.3362, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='You will be assessing the quality of a provided summary in relation to [...] reasoning step by step.' (len=467), mean_score=0.4002, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Assess the quality of a provided summary in relation to a reference te [...] oat between 1 and 5>\\n}' (len=432), mean_score=0.4476, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Assess the quality of a provided summary in relation to a reference te [...] <rating from 1 to 5>\\n}' (len=379), mean_score=0.4627, mean_validation_score=0.4881, zero_score_cases=False),\n",
       " Prompt(prompt='Evaluate the provided summary in comparison to the reference text, foc [...] <rating from 1 to 5>\\n}' (len=389), mean_score=0.3797, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Evaluate the effectiveness of a given summary in comparison to a refer [...] <rating from 1 to 5>\\n}' (len=407), mean_score=0.3524, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Evaluate the effectiveness of a given summary in comparison to a refer [...] <rating from 1 to 5>\\n}' (len=405), mean_score=0.3524, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Evaluate the effectiveness of a given summary in comparison to a refer [...] <rating from 1 to 5>\\n}' (len=386), mean_score=0.4180, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Evaluate the provided summary's effectiveness in capturing the essence [...] <rating from 1 to 5>\\n}' (len=415), mean_score=0.3808, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Evaluate the effectiveness of a given summary in relation to its origi [...] <rating from 1 to 5>\\n}' (len=385), mean_score=0.4249, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Evaluate the provided summary's effectiveness in capturing the essence [...] <rating from 1 to 5>\\n}' (len=427), mean_score=0.4997, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Assess the summary's ability to distill the reference text's core idea [...] <rating from 1 to 5>\\n}' (len=399), mean_score=0.5276, mean_validation_score=0.4881, zero_score_cases=False),\n",
       " Prompt(prompt='Evaluate the summary's effectiveness in capturing the essence of the r [...] <rating from 1 to 5>\\n}' (len=416), mean_score=0.4472, mean_validation_score=None, zero_score_cases=False),\n",
       " Prompt(prompt='Evaluate the summary's effectiveness in capturing the reference text's [...] <rating from 1 to 5>\\n}' (len=422), mean_score=0.4418, mean_validation_score=None, zero_score_cases=False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_set_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prompt(prompt='Please act as an impartial judge and evaluate the quality of the respo [...]  assistant B is better.' (len=915), mean_score=0.8000, mean_validation_score=0.7386, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of a neutral evaluator and assess the quality of the r [...] ssistant B is superior.' (len=1006), mean_score=0.8000, mean_validation_score=0.7727, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of an unbiased evaluator and assess the quality of the [...] ssistant B is superior.' (len=1004), mean_score=0.8000, mean_validation_score=0.8011, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of an unbiased evaluator and assess the quality of the [...] ssistant B is superior.' (len=968), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of an unbiased evaluator and assess the quality of the [...] ssistant B is superior.' (len=1032), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of an unbiased arbiter and assess the quality of the r [...] ssistant B is superior.' (len=964), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of a neutral arbiter and assess the quality of the res [...] ssistant B is superior.' (len=971), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of a neutral evaluator and assess the quality of the r [...] ssistant B is superior.' (len=867), mean_score=0.2000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of an unbiased evaluator and assess the quality of the [...] ssistant B is superior.' (len=1005), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of a neutral evaluator and assess the quality of the r [...] ssistant B is superior.' (len=1000), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of a neutral evaluator and assess the merits of the re [...] ant B is deemed better.' (len=913), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of an unbiased evaluator and assess the quality of the [...] ssistant B is superior.' (len=935), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of a neutral arbiter and assess the quality of the res [...] ssistant B is superior.' (len=1037), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of a neutral evaluator and assess the quality of the r [...] ssistant B is superior.' (len=1005), mean_score=0.2000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of an unbiased arbiter and assess the quality of the r [...] ssistant B is superior.' (len=977), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of a neutral evaluator and assess the quality of the r [...] ssistant B is superior.' (len=910), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of a neutral evaluator and assess the quality of the r [...] ssistant B is superior.' (len=942), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of an unbiased evaluator and assess the quality of the [...] ssistant B is superior.' (len=985), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of an unbiased evaluator and assess the merits of the  [...] ssistant B is superior.' (len=954), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of an unbiased arbiter and assess the quality of the r [...] ssistant B is superior.' (len=953), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True),\n",
       " Prompt(prompt='Assume the role of a neutral arbiter and assess the quality of the res [...] ssistant B is superior.' (len=1030), mean_score=0.8000, mean_validation_score=None, zero_score_cases=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_set_rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9091848552110706, 0.9833243020429444)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from prompt_optimization.utils.prompt import add_embedding_space_representations\n",
    "\n",
    "await add_embedding_space_representations(\n",
    "    prompt_set_se, os.environ[\"PERSONAL_OPENAI_KEY\"]\n",
    ")\n",
    "await add_embedding_space_representations(\n",
    "    prompt_set_rb, os.environ[\"PERSONAL_OPENAI_KEY\"]\n",
    ")\n",
    "\n",
    "embeddings_se = np.array([p.embedding for p in prompt_set_se])\n",
    "embeddings_rb = np.array([p.embedding for p in prompt_set_rb])\n",
    "\n",
    "\n",
    "def average_pairwise_cosine_similarity(embeddings):\n",
    "    # Normalize the vectors\n",
    "    normalized_embeddings = embeddings / np.linalg.norm(\n",
    "        embeddings, axis=1, keepdims=True\n",
    "    )\n",
    "\n",
    "    # Compute the dot product\n",
    "    similarity_matrix = np.dot(normalized_embeddings, normalized_embeddings.T)\n",
    "\n",
    "    # Get the upper triangle of the similarity matrix\n",
    "    upper_tri = np.triu(similarity_matrix, k=1)\n",
    "\n",
    "    # Calculate the average\n",
    "    n = embeddings.shape[0]\n",
    "    average_similarity = np.sum(upper_tri) / (n * (n - 1) / 2)\n",
    "\n",
    "    return average_similarity\n",
    "\n",
    "\n",
    "(\n",
    "    average_pairwise_cosine_similarity(embeddings_se),\n",
    "    average_pairwise_cosine_similarity(embeddings_rb),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199.96491228070175, 237.24285714285713)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Levenshtein import distance\n",
    "\n",
    "\n",
    "def average_pairwise_levenshtein_distance(strings):\n",
    "    \"\"\"Compute the average pairwise Levenshtein distance for a list of strings.\"\"\"\n",
    "    if not strings:\n",
    "        return 0\n",
    "\n",
    "    n = len(strings)\n",
    "    total_distance = 0\n",
    "    pair_count = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            total_distance += distance(strings[i], strings[j])\n",
    "            pair_count += 1\n",
    "\n",
    "    if pair_count == 0:\n",
    "        return 0\n",
    "\n",
    "    return total_distance / pair_count\n",
    "\n",
    "\n",
    "(\n",
    "    average_pairwise_levenshtein_distance([p.prompt for p in prompt_set_se]),\n",
    "    average_pairwise_levenshtein_distance([p.prompt for p in prompt_set_rb]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_perf_incr = [\n",
    "    max(prompt_set_se[: i + 1], key=lambda x: x.mean_score)\n",
    "    for i in range(len(prompt_set_se))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Best performance')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "ax.plot([p.mean_score for p in cum_perf_incr], color=\"blue\")\n",
    "\n",
    "# despine\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# grid\n",
    "ax.yaxis.grid(color=\"gray\", linestyle=\"dashed\")\n",
    "ax.xaxis.grid(color=\"gray\", linestyle=\"dashed\")\n",
    "\n",
    "# labels\n",
    "ax.set_xlabel(\"Optimisation step\")\n",
    "ax.set_ylabel(\"Best performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
